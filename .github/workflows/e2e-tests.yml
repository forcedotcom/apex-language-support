name: E2E Tests

on:
  push:
    branches: [main, tdx26/main, kyledev/e2eTests]
  pull_request:
    branches: [main, tdx26/main]
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test mode (web or desktop)'
        required: false
        default: 'web'
        type: choice
        options:
          - web
          - desktop
          - both

concurrency:
  group: e2e-${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  e2e-tests-web:
    name: E2E ${{ matrix.test_file }} (Web)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: ${{ github.event.inputs.test_mode != 'desktop' }}
    continue-on-error: true

    strategy:
      fail-fast: false
      matrix:
        test_file:
          - apex-extension-core.spec.ts
          - apex-goto-definition.spec.ts
          - apex-hover.spec.ts
          - apex-lsp-integration.spec.ts
          - apex-outline.spec.ts

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build all packages and extension
        run: |
          npm run compile
          npm run bundle

      - name: Verify extension build
        run: |
          if [ ! -f "packages/apex-lsp-vscode-extension/dist/package.json" ]; then
            echo "âŒ package.json not found in dist"
            exit 1
          fi
          if [ ! -f "packages/apex-lsp-vscode-extension/dist/extension.js" ]; then
            echo "âŒ extension.js not found in dist"
            exit 1
          fi
          if [ ! -f "packages/apex-lsp-vscode-extension/dist/extension.web.js" ]; then
            echo "âŒ extension.web.js not found in dist"
            exit 1
          fi
          echo "âœ… Extension build verified"

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Run E2E tests - ${{ matrix.test_file }}
        run: |
          cd e2e-tests
          npx playwright test tests/${{ matrix.test_file }} \
            --project=chromium-web \
            --reporter=line \
            --reporter=junit \
            --reporter=json
        env:
          CI: true
          TEST_MODE: web
          PLAYWRIGHT_HTML_OUTPUT_DIR: playwright-report/${{ matrix.test_file }}
          PLAYWRIGHT_JUNIT_OUTPUT_FILE: test-results/${{ matrix.test_file }}/junit.xml
          PLAYWRIGHT_JSON_OUTPUT_FILE: test-results/${{ matrix.test_file }}/results.json

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-web-${{ matrix.test_file }}-${{ github.run_number }}
          path: e2e-tests/test-results/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-web-${{ matrix.test_file }}-${{ github.run_number }}
          path: e2e-tests/playwright-report/
          retention-days: 30
          if-no-files-found: ignore

      - name: Upload screenshots and videos
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: test-artifacts-web-${{ matrix.test_file }}-${{ github.run_number }}
          path: |
            e2e-tests/test-results/**/*.png
            e2e-tests/test-results/**/*.webm
          retention-days: 30
          if-no-files-found: ignore

  e2e-tests-desktop:
    name: E2E Tests (Desktop Mode)
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    if: ${{ github.event.inputs.test_mode == 'desktop' || github.event.inputs.test_mode == 'both' }}

    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        browser: [chromium]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build all packages and extension
        run: |
          npm run compile
          npm run bundle

      - name: Verify extension build (Unix)
        if: runner.os != 'Windows'
        run: |
          if [ ! -f "packages/apex-lsp-vscode-extension/dist/package.json" ]; then
            echo "âŒ package.json not found in dist"
            exit 1
          fi
          echo "âœ… Extension build verified"

      - name: Verify extension build (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          if (-not (Test-Path "packages/apex-lsp-vscode-extension/dist/package.json")) {
            Write-Host "âŒ package.json not found in dist"
            exit 1
          }
          Write-Host "âœ… Extension build verified"

      - name: Install Playwright browsers
        run: npx playwright install --with-deps ${{ matrix.browser }}

      - name: Run E2E tests (Desktop - ${{ matrix.browser }} on ${{ matrix.os }})
        run: npm run test:e2e:desktop:${{ matrix.browser }} -w e2e-tests
        env:
          CI: true
          TEST_MODE: desktop

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-desktop-${{ matrix.browser }}-${{ matrix.os }}-${{ github.run_number }}
          path: |
            e2e-tests/test-results/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-desktop-${{ matrix.browser }}-${{ matrix.os }}-${{ github.run_number }}
          path: e2e-tests/playwright-report/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload screenshots and videos
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: test-artifacts-desktop-${{ matrix.browser }}-${{ matrix.os }}-${{ github.run_number }}
          path: |
            e2e-tests/test-results/**/*.png
            e2e-tests/test-results/**/*.webm
          retention-days: 30
          if-no-files-found: ignore

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [e2e-tests-web]
    if: always()

    steps:
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          path: test-results/
          merge-multiple: true

      - name: Generate Test Summary
        run: |
          SUMMARY_FILE="e2e-test-summary.md"

          echo "# E2E Test Results Summary ðŸ§ª" >> $SUMMARY_FILE
          echo "" >> $SUMMARY_FILE
          echo "**Run:** [${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $SUMMARY_FILE
          echo "**Branch:** \`${{ github.ref_name }}\`" >> $SUMMARY_FILE
          echo "**Commit:** \`${{ github.sha }}\`" >> $SUMMARY_FILE
          echo "" >> $SUMMARY_FILE

          # Aggregate results from all JUnit XML files (one per test file)
          TOTAL=0
          FAILURES=0
          ERRORS=0
          while IFS= read -r junit; do
            [ -f "$junit" ] || continue
            T=$(grep -o 'tests="[0-9]*"' "$junit" | head -1 | grep -o '[0-9]*' || echo "0")
            F=$(grep -o 'failures="[0-9]*"' "$junit" | head -1 | grep -o '[0-9]*' || echo "0")
            E=$(grep -o 'errors="[0-9]*"' "$junit" | head -1 | grep -o '[0-9]*' || echo "0")
            TOTAL=$((TOTAL + T))
            FAILURES=$((FAILURES + F))
            ERRORS=$((ERRORS + E))
          done < <(find test-results -name "junit.xml" 2>/dev/null || true)

          if [ $TOTAL -gt 0 ]; then
            echo "## Test Results" >> $SUMMARY_FILE
            echo "" >> $SUMMARY_FILE
            PASSED=$((TOTAL - FAILURES - ERRORS))
            echo "- âœ… **Passed:** $PASSED" >> $SUMMARY_FILE
            echo "- âŒ **Failed:** $FAILURES" >> $SUMMARY_FILE
            echo "- âš ï¸ **Errors:** $ERRORS" >> $SUMMARY_FILE
            echo "- ðŸ“Š **Total:** $TOTAL" >> $SUMMARY_FILE
          else
            echo "âš ï¸ No test results found" >> $SUMMARY_FILE
          fi

          echo "" >> $SUMMARY_FILE
          echo "## Artifacts" >> $SUMMARY_FILE
          echo "" >> $SUMMARY_FILE
          echo "View detailed test reports in the [Artifacts](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) section." >> $SUMMARY_FILE

          # Success/Failure badge
          if [ "$FAILURES" = "0" ] && [ "$ERRORS" = "0" ] && [ $TOTAL -gt 0 ]; then
            echo "" >> $SUMMARY_FILE
            echo "### âœ… All tests passed!" >> $SUMMARY_FILE
          elif [ $TOTAL -gt 0 ]; then
            echo "" >> $SUMMARY_FILE
            echo "### âŒ Some tests failed" >> $SUMMARY_FILE
          fi

          # Also write to job summary for Actions UI
          cat $SUMMARY_FILE >> $GITHUB_STEP_SUMMARY

      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summaryFilePath = 'e2e-test-summary.md';
            if (!fs.existsSync(summaryFilePath)) {
              console.log('Test summary file not found, skipping PR comment');
              return;
            }
            const summary = fs.readFileSync(summaryFilePath, 'utf8').trim();
            if (!summary) {
              console.log('Test summary is empty, skipping PR comment');
              return;
            }
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
